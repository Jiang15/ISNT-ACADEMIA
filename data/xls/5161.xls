<html><head><META http-equiv="Content-Type" content="text/html; charset=iso-8859-1"><title></title></head><body bgcolor="#ffffff" marginheight="0" marginwidth="5" link="#666666" vlink="#666666" alink="#666666"><table border="0" width="100%"><tr><th>Projet de master en robotique</th><th style="text-align:left;">Enseignant-e-(s): Profs divers *</th></tr><tr><td colspan="2">Robotique, 2019-2020, Projet Master printemps</td></tr><tr><td colspan="2"><font color="red"></font><table border="0" width="100%"><tr><td>Athanasiadès Cédric Nils</td><td></td><td><table border="0"><tr><td><b>Assistant : </b></td><td>Petr Listov</td></tr><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>19.06.2020</td></tr><tr><td><b>Emplacement PDM : </b></td><td>EPFL</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td></td></tr><tr><td><b>Enseignant : </b></td><td>Jones Colin Neil</td></tr><tr><td><b>Mots-clé : </b></td><td>model predictive control
optimization
polyMPC
embedded
simulation</td></tr><tr><td><b>Résumé : </b></td><td>The aim of the project is to develop an embedded optimization-based algorithm
for the agile flight control of an unmanned aerial vehicle (UAV). The controller
will be implemented in the model predictive control (MPC) fashion for the
nonlinear model of the existing UAV prototype using the PolyMPC library. This
type of control is advantageous in the situation when only a desired geometric
flight path is known. Further, the typical flight envelop constraints and input
constraints can be explicitly handled, making control algorithm more robust
against saturation.
The first milestone of the project would include the optimal control problem
formulation and testing in the existing flight simulator. After that the controller
will to be compiled and deployed on an embedded system. The main concern
when dealing with MPC algorithms is the computational performance and the
limited   memory   available.   Therefore,   the   second   milestone   would   be   to
benchmark performance, tune and, if necessary, improve the solver. Moreover,
different compile optimizations will be explored for a particular embedded
platform.
Finally, the control algorithm will be tested on the autonomous UAV developed
at the laboratory.
If the time allows, a high level interface might be created to simplify the use of
the PolyMPC tool. Currently the problems need to be implemented with modern
C++ and are thus not trivial to use especially for students.
A simple script to define the dynamics, constraints and other parameters would
only need to be written and the code generation, compilation and upload would
be automatically done by the software. The software should also be able to run
the given problem in order to facilitate the debugging.</td></tr></table></td></tr><tr><td>Bailly Xavier Gilbert</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>02.03.2020</td></tr><tr><td><b>Date de fin : </b></td><td>28.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>E.M.S. Electro Medical Systems SA</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Nyon</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Villanueva Torrijo Luis Guillermo</td></tr><tr><td><b>Résumé : </b></td><td>The master student will be integer in the Research and Development group of the dental business unit. His/Her mission will consist to design an optimization algorithm to improve initial design of piezoelectric ultrasonic transducer used in Piezon® products.</td></tr><tr><td><b>Valable pour stage : </b></td><td>Oui</td></tr></table></td></tr><tr><td>Belhadj Bassel</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Kudelski SA</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Cheseaux-Laus Distribution</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Rimoldi Bixio</td></tr><tr><td><b>Mots-clé : </b></td><td>IoT / Machine Learning / Data Analysis</td></tr><tr><td><b>Résumé : </b></td><td>RF fingerprinting is a technique that allows the identification of radio transmitters (such as IoT devices) by analysing the spectrum of their transmissions. 
This analysis can typically be performed using machine learning algorithms. Prior research on this topic exists but has been tested as sub-optimal (i.e. overfitting).</td></tr></table></td></tr><tr><td>Erden Zeki Doruk</td><td></td><td><table border="0"><tr><td><b>Assistant : </b></td><td>Panayiotis Danassis</td></tr><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>19.06.2020</td></tr><tr><td><b>Emplacement PDM : </b></td><td>EPFL</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td></td></tr><tr><td><b>Enseignant : </b></td><td>Faltings Boi</td></tr><tr><td><b>Mots-clé : </b></td><td> multi agent systems, reinforcement learning, machine learning, artificial intelligence, resource allocation</td></tr></table></td></tr><tr><td>Fendri Mohamed Hédi</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Nagra Kudelski Group</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Cheseaux-sur-Lausanne</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Stojilovic Mirjana</td></tr><tr><td><b>Mots-clé : </b></td><td>AI , Machine learning , Deep learning , Cryptographie , Hardware security, Side-channel attacks , </td></tr><tr><td><b>Résumé : </b></td><td>AI and Machine learning to characterize CPU cores instruction set and crypto peripheral based on simulations traces in order to identify weaknesses and define new counter-measure against side channel attacks</td></tr><tr><td><b>Valable pour stage : </b></td><td>Non</td></tr></table></td></tr><tr><td>Frey Sascha Yves</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>19.06.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>University of Chicago</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Autre école</td></tr><tr><td><b>Emplacement PDM - localité (étr.) : </b></td><td>Chicago Illinois</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Etats-Unis</td></tr><tr><td><b>Enseignant : </b></td><td>Jones Colin Neil</td></tr></table></td></tr><tr><td>Frogg Jan Alexander Yamann</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Hublot S.A.</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Nyon</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Boero Giovanni</td></tr><tr><td><b>Valable pour stage : </b></td><td>Oui</td></tr></table></td></tr><tr><td>Hodara Michael</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Logitech Europe SA</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Ecublens VD</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Salzmann Mathieu</td></tr><tr><td><b>Mots-clé : </b></td><td>Robotics, Computer Vision, Computer Graphics, Signal Processing, Tracking, AR, VR, Mixed Reality</td></tr><tr><td><b>Résumé : </b></td><td>Become an expert in the fields of visual inertial odometry (VIO), Simultaneous Localization And Mapping (SLAM) as well as automated system calibration by reviewing existing literature, research, prototypes and products in this field.
Based on the research phase, design, architect and implement algorithms allowing to track the user pose based on a mixed reality head mounted display camera and inertial measurement unit (IMU) as well as object pose based on markers (passive and/or active)
Characterize the resulting system in terms of precision and accuracy</td></tr><tr><td><b>Valable pour stage : </b></td><td>Non</td></tr></table></td></tr><tr><td>Honigmann Simon</td><td></td><td><table border="0"><tr><td><b>Assistant : </b></td><td>Schiano Fabrizio</td></tr><tr><td><b>Date de début : </b></td><td>02.03.2020</td></tr><tr><td><b>Date de fin : </b></td><td>28.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Stanford University</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Autre école</td></tr><tr><td><b>Emplacement PDM - localité (étr.) : </b></td><td>450 Serra Mall, Stanford, Ca 94305, États-Unis</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Etats-Unis</td></tr><tr><td><b>Enseignant : </b></td><td>Floreano Dario</td></tr></table></td></tr><tr><td>Konstantinidi Stefania Maria Aliki</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>EPFL Innovation Park Foundation (EIP)</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Lausanne</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Charbon Edoardo</td></tr><tr><td><b>Mots-clé : </b></td><td>concussion diagnosis, medical device, micro-engineering, NIRS</td></tr><tr><td><b>Résumé : </b></td><td>Our Master Thesis project consists on an entrepreneurial project to be conducted at Innovation Park at EPFL, and was approved by the VPI and the VPE of EPFL. 

The aim of our project is to design a diagnosis helmet helping sport practitioners to behave in a healthy way following a brain concussion. 

As of today, there are no medical imaging modalities capable of detecting concussion, it can only be done is through a pen and paper test that has be done by trained professionals.

Hence, no diagnosis, leads to no proper rest, which leads to a higher risk of repeated brain which leads to Long-term effects and chronic diseases such as Alzheimer et CTE.
</td></tr><tr><td><b>Valable pour stage : </b></td><td>Oui</td></tr></table></td></tr><tr><td>Li Weipeng</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Aspivix SA</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Renens VD</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Renaud Philippe</td></tr><tr><td><b>Mots-clé : </b></td><td>Vacuum-based,  Motorized, Electromechanic, Electronic, 3D manufacturing</td></tr><tr><td><b>Résumé : </b></td><td>Develop a motorized version of vacuum based clamp.</td></tr><tr><td><b>Valable pour stage : </b></td><td>Oui</td></tr></table></td></tr><tr><td>Lippuner Cyrill Florin</td><td></td><td><table border="0"><tr><td><b>Assistant : </b></td><td>Kornatowski Przemyslaw Mariusz</td></tr><tr><td><b>Assistant : </b></td><td>Schiano Fabrizio</td></tr><tr><td><b>Date de début : </b></td><td>02.03.2020</td></tr><tr><td><b>Date de fin : </b></td><td>03.07.2020</td></tr><tr><td><b>Emplacement PDM : </b></td><td>EPFL</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td></td></tr><tr><td><b>Enseignant : </b></td><td>Floreano Dario</td></tr></table></td></tr><tr><td>Lukic Darko</td><td></td><td><table border="0"><tr><td><b>Assistant : </b></td><td>Cyrill Baumann</td></tr><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Cyberbotics Ltd.</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Lausanne</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Martinoli Alcherio</td></tr><tr><td><b>Mots-clé : </b></td><td>simulation, ROS2, e-puck2, Khepera IV, Webots</td></tr><tr><td><b>Résumé : </b></td><td>This master project aims at developing a ROS2 programming interface for the e-puck2 robot and possibly other robots in simulation. The ROS2 programming interface will be implemented on the Raspberry Pi extension of the e-puck2 robot, running Linux. It will support all the sensors and actuators available on the e-puck2 robot. This programming interface will also be implemented in the e-puck2 simulation model of the Webots software, so that the same ROS2 controller will be able to control either the real robot or the simulated one. Example programs displaying basic behavior (obstacle avoidance, line following, wall following, etc.) will be developed in ROS2. The simulated e-puck2 controlled from ROS2 will be calibrated against its real counterpart to minimize the difference of behavior between the simulation and the real world. Optionally, the ROS2 interface of the simulated e-puck2 robot will be extended to support the simulated Khepera IV robot. If ROS2 is available on the real Khepera IV at this point in the project, the transfer of controller from simulation to the real Khepera IV robot will be tested and the simulation model will be further calibrated. Finally, if time permits, these ROS2 simulations will be deployed in Amazon AWS Robomaker, and/or possibly in other robot simulation cloud systems.</td></tr><tr><td><b>Valable pour stage : </b></td><td>Oui</td></tr></table></td></tr><tr><td>Peslerbe Nicolas Pierre Charles</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>02.03.2020</td></tr><tr><td><b>Date de fin : </b></td><td>28.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Synthara AG</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Zürich</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Beuchat René</td></tr><tr><td><b>Résumé : </b></td><td>The goal of the project is to create a system able to take an input image from a camera and forward it out with any faces blurred. The task will be performed running a task-specific CNN on one of Synthara's Deep Learning accelerators, implemented on FPGA. The project milestones are:
 
Identify the state-of-the-art CNN to execute face detection
Prepare the necessary dataset for training
Train a CNN
Take Synthara default FPGA CNN accelerator and evaluate the network inference time
(If necessary) tune the CNN hyperparameters to provide real-time operations on the accelerator
Design the required embedded SW infrastructure to connect the FPGA SoC to a camera and provide the output to a host system
(Optional) Once the basic functionality is achieved, try to replace the FPGA SoC CPU with soft IPs synthesized directly in the FPGA fabric
 
The first part to prepare the CNN is expected to take about 2 months. The basic implementation on the FPGA and the network-tuning other two months, and the final part with soft-IP exploration plus thesis writing other 2 months. The project is expected to start in early March and to finish in September.</td></tr><tr><td><b>Valable pour stage : </b></td><td>Oui</td></tr></table></td></tr><tr><td>Uran Marc</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>24.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>21.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>WeRobotics</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Bern</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Jones Colin Neil</td></tr><tr><td><b>Mots-clé : </b></td><td>Mosquito release mechanism, air flow, temperature/humidity modelisation/control</td></tr><tr><td><b>Résumé : </b></td><td>To store hundreds of thousands of mosquitoes as densely as possible and without damaging them, they have to be stored at 7°C and &lt;60%RH. To control the temperature and humidity, ice-packs and silica are used respectively together with fans that vary the air-flows within the device. The current prototype is holding the desired conditions only with a quite large tolerance. Furthermore, temperature and humidity are not uniform, the air-flows do not reach all areas effectively. To improve the current system, it needs to be analyzed more in depth and modeled. This should lead to an updated setup that fulfills all desired specifications</td></tr><tr><td><b>Valable pour stage : </b></td><td>Oui</td></tr></table></td></tr><tr><td>Wälti Lucas Cédric</td><td></td><td><table border="0"><tr><td><b>Date de début : </b></td><td>17.02.2020</td></tr><tr><td><b>Date de fin : </b></td><td>14.08.2020</td></tr><tr><td><b>Ecole/entreprise : </b></td><td>Schindler Aufzüge AG</td></tr><tr><td><b>Emplacement PDM : </b></td><td>Entreprise</td></tr><tr><td><b>Emplacement PDM - localité (suisse) : </b></td><td>Lausanne</td></tr><tr><td><b>Emplacement PDM - pays : </b></td><td>Suisse</td></tr><tr><td><b>Enseignant : </b></td><td>Jones Colin Neil</td></tr><tr><td><b>Mots-clé : </b></td><td>Autonomous flight, drone, navigation, computer vision, localization </td></tr><tr><td><b>Résumé : </b></td><td>This project aims at implementing an autonomous drone for elevator shafts inspection. The drone should only require high level commands from the operator, such as going one story up or reaching the elevator's motor. A fully autonomous inspection procedure could be envisioned. 
Furthermore, computer vision pipelines could be added to autonomously monitor the state of the shaft and automatically produce diagnostics. </td></tr><tr><td><b>Valable pour stage : </b></td><td>Non</td></tr></table></td></tr></table></td></tr><tr><td colspan="2"><font color="red"></font><table border="0" width="100%"></table></td></tr></table></body></html>
<!-- OpenXml:0.01s  agent ctrl:0.00s  xml:0.13s  xsl extr&stylesheet:0.00s  xsl after parsing:0.00s  xsl ctrl data:0.00s  transform 2:0.02s  xsl process:0.00s  -->